# Multimodal Chatbot with RAG & LLM
---

## Features

- ğŸ“„ **PDF Understanding**: Upload PDFs and ask questions about the content.
- ğŸ–¼ï¸ **Image Analysis**: Upload an image and ask questions related to it.
- ğŸ’¬ **Text Queries**: Ask general questions with or without PDF/image context.
- âš¡ **RAG Pipeline**: Relevant PDF chunks retrieved via **FAISS + SentenceTransformer**.
- ğŸ§  **Reasoning Memory**: Maintains conversation context across queries.
- ğŸ”— **OpenRouter LLM Integration**: Uses free LLMs for text & multimodal reasoning.

---

## Tech Stack

- **Backend**: FastAPI, Python
- **Frontend**: React + Vite
- **Embeddings**: `SentenceTransformer` (`all-MiniLM-L6-v2`)
- **Vector Store**: FAISS
- **LLM**: OpenRouter API (`nvidia/nemotron-nano-12b-v2-vl:free`)
- **File Handling**: PDF (`pdfplumber`), Image upload
- **Environment Management**: `.env` (contains your API key)

---

## Installation
```bash

### Backend

# Start FastAPI server
python -m uvicorn backend.main:app --reload

### Frontend

cd frontend
npm install
npm run dev

---

## Project Structure:

backend/
 â”œâ”€ core/
 â”‚   â”œâ”€ llm.py        # LLM call & reasoning memory
 â”‚   â”œâ”€ rag.py        # FAISS embeddings & PDF retrieval
 â”‚   â””â”€ embedding.py  # SentenceTransformer embeddings
 â”œâ”€ routers/
 â”‚   â”œâ”€ chat.py       # Chat API
 â”‚   â””â”€ upload.py     # PDF/Image upload API
 â”œâ”€ storage/
 â”‚   â”œâ”€ faiss_index/  # FAISS index and chunks
 â”‚   â””â”€ uploads/      # Uploaded files
 â””â”€ main.py           # FastAPI app
frontend/
 â”œâ”€ src/
 â””â”€ vite.config.js

---

